# -*- coding: utf-8 -*-
"""electricity_sales_model_dev.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y8rJy4M_RMRL_F0riOXcnkixjZtpDcsY

# Import Libraries
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import seaborn as sns
import matplotlib.pyplot as plt

"""# 1. Data Collection"""

import requests
import pandas as pd

api_key = "Koh9jiaj4KRMH9Afbk6NCYuX8BgSsqGjnePQf7Hl"


url = (
    "https://api.eia.gov/v2/electricity/retail-sales/data/"
    "?frequency=monthly"
    "&data[0]=customers"
    "&data[1]=price"
    "&data[2]=revenue"
    "&data[3]=sales"
    "&sort[0][column]=period&sort[0][direction]=desc"
    "&offset=0"
    "&length=5000"
    f"&api_key={api_key}"
)

response = requests.get(url)
data = response.json()

# Extract data if present
if 'response' in data and 'data' in data['response']:
    records = data['response']['data']
    df = pd.DataFrame(records)

    # Optional: Convert date and sort
    df['period'] = pd.to_datetime(df['period'])
    df = df.sort_values('period')

df.head()

"""# 2. Data Cleaning"""

df.info()

df.isnull().sum()

cols_to_convert = ['customers', 'price', 'revenue', 'sales']

for col in cols_to_convert:
    df[col] = df[col].str.replace(',', '')  # remove commas
    df[col] = pd.to_numeric(df[col], errors='coerce')  # convert to float, NaN if error

df.info()

df = df.dropna(subset=['customers'])
df['customers'] = df['customers'].astype(int)

df.isnull().sum()

df.info()

df.drop_duplicates(inplace=True)

df.reset_index(drop=True, inplace=True)

Q1 = df['sales'].quantile(0.25)
Q3 = df['sales'].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Find outliers
outliers = df[(df['sales'] < lower_bound) | (df['sales'] > upper_bound)]

print(f"Number of outliers in 'sales': {len(outliers)}")

# Check for nulls again
print(df.isnull().sum())

# Confirm data types
print(df.dtypes)

# Confirm shape and preview
print(df.shape)
print(df.head())

"""# 3. Data Storage

"""

import os
os.makedirs('/content/drive/MyDrive', exist_ok=True)

# Save to Google Drive as CSV
df.to_csv('/content/drive/MyDrive/cleaned_energy_data.csv', index=False)

"""# Exploraty Data Analysis

"""

# ðŸŸ¨ Filter out "all sectors" from sectors
df_filtered_sectors = df[df['sectorName'] != 'all sectors']

# Group and prepare sector sales data (excluding all sectors)
sector_sales = df_filtered_sectors.groupby('sectorName')['sales']\
    .sum().sort_values(ascending=False)

# Plot sector sales
plt.figure(figsize=(8, 5))
sns.barplot(x=sector_sales.values, y=sector_sales.index, palette='magma')
plt.title("Electricity Sales by Sector (Excl. All Sectors)")
plt.xlabel("Total Sales")
plt.ylabel("Sector")
plt.tight_layout()
plt.show()

df['month'] = pd.to_datetime(df['period']).dt.month
monthly_sales = df.groupby('month')['sales'].mean()

monthly_sales.plot(kind='line', title='Average Monthly Electricity Sales')
plt.xlabel('Month')
plt.ylabel('Sales')
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# ðŸŸ¦ Filter out "U.S. Total" from states
df_filtered_states = df[df['stateDescription'] != 'U.S. Total']

# Group and prepare state sales data (excluding U.S. Total)
state_sales = df_filtered_states.groupby('stateDescription')['sales']\
    .sum().sort_values(ascending=False).head(10)

# Plot state sales
plt.figure(figsize=(10, 6))
sns.barplot(x=state_sales.values, y=state_sales.index, palette='viridis')
plt.title("Top 10 States by Total Electricity Sales (Excl. U.S. Total)")
plt.xlabel("Total Sales")
plt.ylabel("State")
plt.tight_layout()
plt.show()

import seaborn as sns
sns.scatterplot(data=df, x='price', y='sales')
plt.title("Price vs Sales")
plt.show()

"""# 4. Preprocessing & Feature Engineering"""

from google.colab import drive
import pandas as pd

# Load the cleaned data from the CSV file
df = pd.read_csv('/content/drive/MyDrive/cleaned_energy_data.csv')

# 2. Convert 'period' if needed
df['period'] = pd.to_datetime(df['period'], errors='coerce')

# 3. Extract date parts if useful
df['year'] = df['period'].dt.year
df['month'] = df['period'].dt.month

# 4. Drop non-numeric or unused columns
df = df.drop(columns=['period', 'sales-units', 'price-units', 'revenue-units', 'customers-units', 'stateDescription', 'sectorName'])

# 5. One-hot encode
df = pd.get_dummies(df, columns=['stateid', 'sectorid'], drop_first=True)

# 6. Define features and target
X = df.drop('sales', axis=1)
y = df['sales']

# 7. Double-check datatypes
print(X.dtypes[~X.dtypes.isin(['float64', 'int64'])])  # should return empty

import seaborn as sns
import matplotlib.pyplot as plt

sns.histplot(df['sales'], kde=True)
plt.title('Sales Distribution')
plt.show()

df.corr(numeric_only=True)['sales'].sort_values(ascending=False)

sns.boxplot(x=df['sales'])

"""# 5. Modeling"""

X = df.drop('sales', axis=1)
y = df['sales']

X = X.drop(columns=['revenue'])

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Predict
y_pred_lr = lr_model.predict(X_test)

"""# 6. Evaluation"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

def evaluate_model(y_true, y_pred):
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)

    print("ðŸ”¹ Model Evaluation:")
    print(f"MAE: {mae:.2f}")
    print(f"RMSE: {rmse:.2f}")
    print(f"RÂ²: {r2:.4f}")

rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X_train, y_train)

# Predict
y_pred_rf = rf_model.predict(X_test)

print("ðŸ”¹ Random Forest Performance:")
evaluate_model(y_test, y_pred_rf)

import matplotlib.pyplot as plt

plt.scatter(y_test, y_pred_rf)
plt.xlabel("Actual Sales")
plt.ylabel("Predicted Sales")
plt.title("Random Forest: Actual vs Predicted")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Get feature importances
importances = rf_model.feature_importances_
feature_names = X.columns
feat_imp = pd.Series(importances, index=feature_names).sort_values(ascending=False)

# Plot top 10
feat_imp.head(10).plot(kind='barh', title='Top 10 Feature Importances', figsize=(8,5))
plt.gca().invert_yaxis()
plt.show()

"""# 7. Saving The Model"""

import joblib

joblib.dump(rf_model, 'model.joblib')

